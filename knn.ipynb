{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inisiasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "data_input = pd.read_csv('data/test.csv')\n",
    "\n",
    "data_result = {'id':[],'price_range':[]}\n",
    "correlation = {}\n",
    "data_min = {}\n",
    "data_max = {}\n",
    "columns = data_train.columns\n",
    "non_numeric = [\"blue\",\"dual_sim\",\"four_g\",\"three_g\",\"touch_screen\",\"wifi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korelasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlation(corr,data_min,data_max,columns, data_train,non_numeric):\n",
    "    for i in columns:\n",
    "        if(i in non_numeric):\n",
    "            correlation, p_value = pointbiserialr(data_train[i], data_train['price_range'])\n",
    "            corr[i]=correlation\n",
    "        else :\n",
    "            corr[i]=data_train[i].corr(data_train['price_range'])\n",
    "    for i in columns:\n",
    "        data_min[i]=data_train[i].min()\n",
    "    for i in columns:\n",
    "        data_max[i]=data_train[i].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_correlation(correlation,data_min,data_max,columns, data_train,non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data,data_min,data_max,correlation,columns):\n",
    "    for i in columns:\n",
    "        if(i!='price_range'):\n",
    "            data[i]=10*abs(correlation[i])*(data[i]-data_min[i])/(data_max[i]-data_min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(data_train,data_min,data_max,correlation,columns)\n",
    "normalize(data_input,data_min,data_max,correlation,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance between 2 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(data1, data2, row1, row2):\n",
    "    columns=data1.columns\n",
    "    res = 0\n",
    "    for i in columns:\n",
    "        if i != 'price_range' and i != 'id':\n",
    "            res += (data1.loc[row1, i] - data2.loc[row2, i]) ** 2\n",
    "    return res ** (1/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_point(input_data,train_data,k,point) :\n",
    "    arr = []\n",
    "    for i in range(len(train_data)) :\n",
    "        arr.append([distance(input_data, train_data, point,i),train_data.loc[i,'price_range']])\n",
    "    arr.sort(key=lambda x: x[0])\n",
    "    arr = arr[:k]\n",
    "    count = [0,0,0,0]\n",
    "    for i in arr :\n",
    "        count[i[1]]+=1\n",
    "    return count.index(max(count))\n",
    "\n",
    "def accuracy(data_input,data_train,k) :\n",
    "    count = 0\n",
    "    for i in range(len(data_input)) :\n",
    "        if(classify_point(data_input,data_train,k,i)==data_input.loc[i,'price_range']) :\n",
    "            count+=1\n",
    "    return count/len(data_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate knn with input k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_k(input_data,train_data,result_data,k) :\n",
    "    for i in range(len(input_data)):\n",
    "        result_data['id'].append(i)\n",
    "        result_data['price_range'].append(classify_point(input_data, train_data, k, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(result_data, file_name) :\n",
    "    result_data.to_csv(f'data/{file_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_k(data_input,data_train,data_result,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(pd.DataFrame(data_result),\"res3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model Using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(input_data,train_data,k) :\n",
    "    #pre processing\n",
    "    data_train=train_data.copy()\n",
    "    data_input=input_data.copy()\n",
    "    columns = data_train.columns\n",
    "\n",
    "    data_result = {'id':[],'price_range':[]}\n",
    "    correlation = {}\n",
    "    data_min = {}\n",
    "    data_max = {}\n",
    "    non_numeric = [\"blue\",\"dual_sim\",\"four_g\",\"three_g\",\"touch_screen\",\"wifi\"]\n",
    "    result_data = {'id':[],'price_range':[]}\n",
    "\n",
    "    find_correlation(correlation,data_min,data_max,columns,data_train,non_numeric)\n",
    "\n",
    "    normalize(data_train,data_min,data_max,correlation,columns)\n",
    "    normalize(data_input,data_min,data_max,correlation,columns)\n",
    "    \n",
    "    iterate_k(input_data,train_data,result_data,k)\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_function(func, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        dill.dump(func, file)\n",
    "\n",
    "save_function((iterate, iterate_k, classify_point, distance, find_correlation, normalize, pointbiserialr ), 'model/KNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'price_range': [0, 3, 3, 2, 0, 0, 2, 3, 0, 2]}\n"
     ]
    }
   ],
   "source": [
    "def load_function(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return dill.load(file)\n",
    "\n",
    "iterate, iterate_k, classify_point, distance, find_correlation, normalize,pointbiserialr = load_function('model/knn.pkl')\n",
    "\n",
    "train=pd.read_csv('data/data_train.csv')\n",
    "inputs=pd.read_csv('data/test.csv')\n",
    "result = iterate(inputs[:10], train, 3)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dee9a514957ef8877214c92483596850de1c8f460a98fef942676ebd5d14e9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
